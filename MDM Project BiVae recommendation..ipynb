{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import cornac\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as sk_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def python_random_split(data, ratio=0.75, seed=42):\n",
    "    \"\"\"Pandas random splitter.\n",
    "    The splitter randomly splits the input data.\n",
    "    Args:\n",
    "        data (pandas.DataFrame): Pandas DataFrame to be split.\n",
    "        ratio (float or list): Ratio for splitting data. If it is a single float number\n",
    "            it splits data into two halves and the ratio argument indicates the ratio\n",
    "            of training data set; if it is a list of float numbers, the splitter splits\n",
    "            data into several portions corresponding to the split ratios. If a list is\n",
    "            provided and the ratios are not summed to 1, they will be normalized.\n",
    "        seed (int): Seed.\n",
    "    Returns:\n",
    "        list: Splits of the input data as pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    multi_split, ratio = process_split_ratio(ratio)\n",
    "\n",
    "    if multi_split:\n",
    "        splits = split_pandas_data_with_ratios(data, ratio, shuffle=True, seed=seed)\n",
    "        splits_new = [x.drop(\"split_index\", axis=1) for x in splits]\n",
    "\n",
    "        return splits_new\n",
    "    else:\n",
    "        return sk_split(data, test_size=None, train_size=ratio, random_state=seed)\n",
    "    \n",
    "def process_split_ratio(ratio):\n",
    "    \"\"\"Generate split ratio lists.\n",
    "    Args:\n",
    "        ratio (float or list): a float number that indicates split ratio or a list of float\n",
    "        numbers that indicate split ratios (if it is a multi-split).\n",
    "    Returns:\n",
    "        tuple:\n",
    "        - bool: A boolean variable multi that indicates if the splitting is multi or single.\n",
    "        - list: A list of normalized split ratios.\n",
    "    \"\"\"\n",
    "    if isinstance(ratio, float):\n",
    "        if ratio <= 0 or ratio >= 1:\n",
    "            raise ValueError(\"Split ratio has to be between 0 and 1\")\n",
    "\n",
    "        multi = False\n",
    "    elif isinstance(ratio, list):\n",
    "        if any([x <= 0 for x in ratio]):\n",
    "            raise ValueError(\n",
    "                \"All split ratios in the ratio list should be larger than 0.\"\n",
    "            )\n",
    "\n",
    "        # normalize split ratios if they are not summed to 1\n",
    "        if math.fsum(ratio) != 1.0:\n",
    "            ratio = [x / math.fsum(ratio) for x in ratio]\n",
    "\n",
    "        multi = True\n",
    "    else:\n",
    "        raise TypeError(\"Split ratio should be either float or a list of floats.\")\n",
    "\n",
    "    return multi, ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer\n",
    "\n",
    "\n",
    "DEFAULT_USER_COL = \"userID\"\n",
    "DEFAULT_ITEM_COL = \"itemID\"\n",
    "DEFAULT_PREDICTION_COL = \"prediction\"\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"Timer class.\n",
    "    `Original code <https://github.com/miguelgfierro/pybase/blob/2298172a13fb4a243754acbc6029a4a2dcf72c20/log_base/timer.py>`_.\n",
    "    Examples:\n",
    "        >>> import time\n",
    "        >>> t = Timer()\n",
    "        >>> t.start()\n",
    "        >>> time.sleep(1)\n",
    "        >>> t.stop()\n",
    "        >>> t.interval < 1\n",
    "        True\n",
    "        >>> with Timer() as t:\n",
    "        ...   time.sleep(1)\n",
    "        >>> t.interval < 1\n",
    "        True\n",
    "        >>> \"Time elapsed {}\".format(t) #doctest: +ELLIPSIS\n",
    "        'Time elapsed 1...'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "        self._interval = 0\n",
    "        self.running = False\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{:0.4f}\".format(self.interval)\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.init = self._timer()\n",
    "        self.running = True\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        try:\n",
    "            self._interval = self.end - self.init\n",
    "            self.running = False\n",
    "        except AttributeError:\n",
    "            raise ValueError(\n",
    "                \"Timer has not been initialized: use start() or the contextual form with Timer() as t:\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def interval(self):\n",
    "        \"\"\"Get time interval in seconds.\n",
    "        Returns:\n",
    "            float: Seconds.\n",
    "        \"\"\"\n",
    "        if self.running:\n",
    "            raise ValueError(\"Timer has not been stopped, please use stop().\")\n",
    "        else:\n",
    "            return self._interval\n",
    "\n",
    "def predict_ranking(\n",
    "    model,\n",
    "    data,\n",
    "    usercol=DEFAULT_USER_COL,\n",
    "    itemcol=DEFAULT_ITEM_COL,\n",
    "    predcol=DEFAULT_PREDICTION_COL,\n",
    "    remove_seen=False,\n",
    "):\n",
    "    \"\"\"Computes predictions of recommender model from Cornac on all users and items in data.\n",
    "    It can be used for computing ranking metrics like NDCG.\n",
    "    Args:\n",
    "        model (cornac.models.Recommender): A recommender model from Cornac\n",
    "        data (pandas.DataFrame): The data from which to get the users and items\n",
    "        usercol (str): Name of the user column\n",
    "        itemcol (str): Name of the item column\n",
    "        remove_seen (bool): Flag to remove (user, item) pairs seen in the training data\n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe with usercol, itemcol, predcol\n",
    "    \"\"\"\n",
    "    users, items, preds = [], [], []\n",
    "    item = list(model.train_set.iid_map.keys())\n",
    "    for uid, user_idx in model.train_set.uid_map.items():\n",
    "        user = [uid] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        preds.extend(model.score(user_idx).tolist())\n",
    "\n",
    "    all_predictions = pd.DataFrame(\n",
    "        data={usercol: users, itemcol: items, predcol: preds}\n",
    "    )\n",
    "\n",
    "    if remove_seen:\n",
    "        tempdf = pd.concat(\n",
    "            [\n",
    "                data[[usercol, itemcol]],\n",
    "                pd.DataFrame(\n",
    "                    data=np.ones(data.shape[0]), columns=[\"dummycol\"], index=data.index\n",
    "                ),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        merged = pd.merge(tempdf, all_predictions, on=[usercol, itemcol], how=\"outer\")\n",
    "        return merged[merged[\"dummycol\"].isnull()].drop(\"dummycol\", axis=1)\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select MovieLens data size: 100k, 1m, 10m, or 20m\n",
    "MOVIELENS_DATA_SIZE = '100k'\n",
    "\n",
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "LATENT_DIM = 50\n",
    "ENCODER_DIMS = [100]\n",
    "ACT_FUNC = \"tanh\"\n",
    "LIKELIHOOD = \"pois\"\n",
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>349</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>356</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>457</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>527</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>543</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100806</th>\n",
       "      <td>610</td>\n",
       "      <td>150401</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100807</th>\n",
       "      <td>610</td>\n",
       "      <td>152077</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100808</th>\n",
       "      <td>610</td>\n",
       "      <td>152081</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100809</th>\n",
       "      <td>610</td>\n",
       "      <td>152372</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100810</th>\n",
       "      <td>610</td>\n",
       "      <td>155064</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100811</th>\n",
       "      <td>610</td>\n",
       "      <td>156371</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100812</th>\n",
       "      <td>610</td>\n",
       "      <td>156726</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100813</th>\n",
       "      <td>610</td>\n",
       "      <td>157296</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100814</th>\n",
       "      <td>610</td>\n",
       "      <td>158238</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100815</th>\n",
       "      <td>610</td>\n",
       "      <td>158721</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100816</th>\n",
       "      <td>610</td>\n",
       "      <td>158872</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>610</td>\n",
       "      <td>158956</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100818</th>\n",
       "      <td>610</td>\n",
       "      <td>159093</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100819</th>\n",
       "      <td>610</td>\n",
       "      <td>160080</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100820</th>\n",
       "      <td>610</td>\n",
       "      <td>160341</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100821</th>\n",
       "      <td>610</td>\n",
       "      <td>160527</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100822</th>\n",
       "      <td>610</td>\n",
       "      <td>160571</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100823</th>\n",
       "      <td>610</td>\n",
       "      <td>160836</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>610</td>\n",
       "      <td>161582</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100825</th>\n",
       "      <td>610</td>\n",
       "      <td>161634</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100826</th>\n",
       "      <td>610</td>\n",
       "      <td>162350</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100827</th>\n",
       "      <td>610</td>\n",
       "      <td>163937</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100828</th>\n",
       "      <td>610</td>\n",
       "      <td>163981</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100829</th>\n",
       "      <td>610</td>\n",
       "      <td>164179</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100830</th>\n",
       "      <td>610</td>\n",
       "      <td>166528</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID  itemID  rating\n",
       "0            1       1     4.0\n",
       "1            1       3     4.0\n",
       "2            1       6     4.0\n",
       "3            1      47     5.0\n",
       "4            1      50     5.0\n",
       "5            1      70     3.0\n",
       "6            1     101     5.0\n",
       "7            1     110     4.0\n",
       "8            1     151     5.0\n",
       "9            1     157     5.0\n",
       "10           1     163     5.0\n",
       "11           1     216     5.0\n",
       "12           1     223     3.0\n",
       "13           1     231     5.0\n",
       "14           1     235     4.0\n",
       "15           1     260     5.0\n",
       "16           1     296     3.0\n",
       "17           1     316     3.0\n",
       "18           1     333     5.0\n",
       "19           1     349     4.0\n",
       "20           1     356     4.0\n",
       "21           1     362     5.0\n",
       "22           1     367     4.0\n",
       "23           1     423     3.0\n",
       "24           1     441     4.0\n",
       "25           1     457     5.0\n",
       "26           1     480     4.0\n",
       "27           1     500     3.0\n",
       "28           1     527     5.0\n",
       "29           1     543     4.0\n",
       "...        ...     ...     ...\n",
       "100806     610  150401     3.0\n",
       "100807     610  152077     4.0\n",
       "100808     610  152081     4.0\n",
       "100809     610  152372     3.5\n",
       "100810     610  155064     3.5\n",
       "100811     610  156371     5.0\n",
       "100812     610  156726     4.5\n",
       "100813     610  157296     4.0\n",
       "100814     610  158238     5.0\n",
       "100815     610  158721     3.5\n",
       "100816     610  158872     3.5\n",
       "100817     610  158956     3.0\n",
       "100818     610  159093     3.0\n",
       "100819     610  160080     3.0\n",
       "100820     610  160341     2.5\n",
       "100821     610  160527     4.5\n",
       "100822     610  160571     3.0\n",
       "100823     610  160836     3.0\n",
       "100824     610  161582     4.0\n",
       "100825     610  161634     4.0\n",
       "100826     610  162350     3.5\n",
       "100827     610  163937     3.5\n",
       "100828     610  163981     3.5\n",
       "100829     610  164179     5.0\n",
       "100830     610  166528     4.0\n",
       "100831     610  166534     4.0\n",
       "100832     610  168248     5.0\n",
       "100833     610  168250     5.0\n",
       "100834     610  168252     5.0\n",
       "100835     610  170875     3.0\n",
       "\n",
       "[100836 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\\\Rutgers\\\\CS550 MDM\\\\project\\\\project\\\\ml-latest-small\\\\ratings.csv')\n",
    "data = data.drop(columns=['timestamp'])\n",
    "data = data.rename(columns={\"movieId\": \"itemID\",\"userId\":\"userID\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = python_random_split(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610\n",
      "Number of items: 8787\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)\n",
    "\n",
    "print('Number of users: {}'.format(train_set.num_users))\n",
    "print('Number of items: {}'.format(train_set.num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55d75226fde4569ad254d77bed6db0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 463.1656 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "bivae = cornac.models.BiVAECF(\n",
    "    k=LATENT_DIM,\n",
    "    encoder_structure=ENCODER_DIMS,\n",
    "    act_fn=ACT_FUNC,\n",
    "    likelihood=LIKELIHOOD,\n",
    "    n_epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    seed=SEED,\n",
    "    use_gpu=torch.cuda.is_available(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "with Timer() as t:\n",
    "    bivae.fit(train_set)\n",
    "print(\"Took {} seconds for training.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 5.7424 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with Timer() as t:\n",
    "    all_predictions = predict_ranking(bivae, train, usercol='userID', itemcol='itemID', remove_seen=True)\n",
    "print(\"Took {} seconds for prediction.\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    explained_variance_score,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    ")\n",
    "\n",
    "DEFAULT_RATING_COL = \"rating\"\n",
    "DEFAULT_RELEVANCE_COL = \"relevance\"\n",
    "DEFAULT_SIMILARITY_COL = \"sim\"\n",
    "DEFAULT_ITEM_FEATURES_COL = \"features\"\n",
    "DEFAULT_ITEM_SIM_MEASURE = \"item_cooccurrence_count\"\n",
    "DEFAULT_K = 10\n",
    "DEFAULT_THRESHOLD = 10\n",
    "\n",
    "def precision_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Precision at K.\n",
    "    Note:\n",
    "        We use the same formula to calculate precision@k as that in Spark.\n",
    "        More details can be found at\n",
    "        http://spark.apache.org/docs/2.1.1/api/python/pyspark.mllib.html#pyspark.mllib.evaluation.RankingMetrics.precisionAt\n",
    "        In particular, the maximum achievable precision may be < 1, if the number of items for a\n",
    "        user in rating_pred is less than k.\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "    Returns:\n",
    "        float: precision at k (min=0, max=1)\n",
    "    \"\"\"\n",
    "\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (df_hit_count[\"hit\"] / k).sum() / n_users\n",
    "\n",
    "def recall_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Recall at K.\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "    Returns:\n",
    "        float: recall at k (min=0, max=1). The maximum value is 1 even when fewer than\n",
    "        k items exist for a user in rating_true.\n",
    "    \"\"\"\n",
    "\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (df_hit_count[\"hit\"] / df_hit_count[\"actual\"]).sum() / n_users\n",
    "\n",
    "def ndcg_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Normalized Discounted Cumulative Gain (nDCG).\n",
    "    Info: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "    Returns:\n",
    "        float: nDCG at k (min=0, max=1).\n",
    "    \"\"\"\n",
    "\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # calculate discounted gain for hit items\n",
    "    df_dcg = df_hit.copy()\n",
    "    # relevance in this case is always 1\n",
    "    df_dcg[\"dcg\"] = 1 / np.log1p(df_dcg[\"rank\"])\n",
    "    # sum up discount gained to get discount cumulative gain\n",
    "    df_dcg = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
    "    # calculate ideal discounted cumulative gain\n",
    "    df_ndcg = pd.merge(df_dcg, df_hit_count, on=[col_user])\n",
    "    df_ndcg[\"idcg\"] = df_ndcg[\"actual\"].apply(\n",
    "        lambda x: sum(1 / np.log1p(range(1, min(x, k) + 1)))\n",
    "    )\n",
    "\n",
    "    # DCG over IDCG is the normalized DCG\n",
    "    return (df_ndcg[\"dcg\"] / df_ndcg[\"idcg\"]).sum() / n_users\n",
    "\n",
    "def map_at_k(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user=DEFAULT_USER_COL,\n",
    "    col_item=DEFAULT_ITEM_COL,\n",
    "    col_rating=DEFAULT_RATING_COL,\n",
    "    col_prediction=DEFAULT_PREDICTION_COL,\n",
    "    relevancy_method=\"top_k\",\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Mean Average Precision at k\n",
    "    The implementation of MAP is referenced from Spark MLlib evaluation metrics.\n",
    "    https://spark.apache.org/docs/2.3.0/mllib-evaluation-metrics.html#ranking-systems\n",
    "    A good reference can be found at:\n",
    "    http://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    Note:\n",
    "        1. The evaluation function is named as 'MAP is at k' because the evaluation class takes top k items for\n",
    "        the prediction items. The naming is different from Spark.\n",
    "        2. The MAP is meant to calculate Avg. Precision for the relevant items, so it is normalized by the number of\n",
    "        relevant items in the ground truth data, instead of k.\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "    Returns:\n",
    "        float: MAP at k (min=0, max=1).\n",
    "    \"\"\"\n",
    "\n",
    "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "        relevancy_method=relevancy_method,\n",
    "        k=k,\n",
    "        threshold=threshold,\n",
    "    )\n",
    "\n",
    "    if df_hit.shape[0] == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # calculate reciprocal rank of items for each user and sum them up\n",
    "    df_hit_sorted = df_hit.copy()\n",
    "    df_hit_sorted[\"rr\"] = (\n",
    "        df_hit_sorted.groupby(col_user).cumcount() + 1\n",
    "    ) / df_hit_sorted[\"rank\"]\n",
    "    df_hit_sorted = df_hit_sorted.groupby(col_user).agg({\"rr\": \"sum\"}).reset_index()\n",
    "\n",
    "    df_merge = pd.merge(df_hit_sorted, df_hit_count, on=col_user)\n",
    "    return (df_merge[\"rr\"] / df_merge[\"actual\"]).sum() / n_users\n",
    "\n",
    "def merge_ranking_true_pred(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "    relevancy_method,\n",
    "    k=DEFAULT_K,\n",
    "    threshold=DEFAULT_THRESHOLD,\n",
    "):\n",
    "    \"\"\"Filter truth and prediction data frames on common users\n",
    "    Args:\n",
    "        rating_true (pandas.DataFrame): True DataFrame\n",
    "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
    "        col_user (str): column name for user\n",
    "        col_item (str): column name for item\n",
    "        col_rating (str): column name for rating\n",
    "        col_prediction (str): column name for prediction\n",
    "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
    "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
    "        k (int): number of top k items per user (optional)\n",
    "        threshold (float): threshold of top items per user (optional)\n",
    "    Returns:\n",
    "        pandas.DataFrame, pandas.DataFrame, int: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n",
    "        DataFrame of hit counts vs actual relevant items per user number of unique user ids\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the prediction and true data frames have the same set of users\n",
    "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
    "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
    "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
    "    n_users = len(common_users)\n",
    "\n",
    "    # Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.\n",
    "    # Use first to generate unique ranking values for each item. This is to align with the implementation in\n",
    "    # Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used\n",
    "    # to calculate penalized precision of the ordered items.\n",
    "    if relevancy_method == \"top_k\":\n",
    "        top_k = k\n",
    "    elif relevancy_method == \"by_threshold\":\n",
    "        top_k = threshold\n",
    "    elif relevancy_method is None:\n",
    "        top_k = None\n",
    "    else:\n",
    "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
    "    df_hit = get_top_k_items(\n",
    "        dataframe=rating_pred_common,\n",
    "        col_user=col_user,\n",
    "        col_rating=col_prediction,\n",
    "        k=top_k,\n",
    "    )\n",
    "    df_hit = pd.merge(df_hit, rating_true_common, on=[col_user, col_item])[\n",
    "        [col_user, col_item, \"rank\"]\n",
    "    ]\n",
    "\n",
    "    # count the number of hits vs actual relevant items per user\n",
    "    df_hit_count = pd.merge(\n",
    "        df_hit.groupby(col_user, as_index=False)[col_user].agg({\"hit\": \"count\"}),\n",
    "        rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
    "            {\"actual\": \"count\"}\n",
    "        ),\n",
    "        on=col_user,\n",
    "    )\n",
    "\n",
    "    return df_hit, df_hit_count, n_users\n",
    "\n",
    "def get_top_k_items(\n",
    "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
    "):\n",
    "    \"\"\"Get the input customer-item-rating tuple in the format of Pandas\n",
    "    DataFrame, output a Pandas DataFrame in the dense format of top k items\n",
    "    for each user.\n",
    "    Note:\n",
    "        If it is implicit rating, just append a column of constants to be\n",
    "        ratings.\n",
    "    Args:\n",
    "        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n",
    "        customerID-itemID-rating)\n",
    "        col_user (str): column name for user\n",
    "        col_rating (str): column name for rating\n",
    "        k (int or None): number of items for each user; None means that the input has already been\n",
    "        filtered out top k items and sorted by ratings and there is no need to do that again.\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
    "    \"\"\"\n",
    "    # Sort dataframe by col_user and (top k) col_rating\n",
    "    if k is None:\n",
    "        top_k_items = dataframe\n",
    "    else:\n",
    "        top_k_items = (\n",
    "            dataframe.groupby(col_user, as_index=False)\n",
    "            .apply(lambda x: x.nlargest(k, col_rating))\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "    # Add ranks\n",
    "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
    "    return top_k_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.099130\n",
      "NDCG:\t0.381835\n",
      "Precision@K:\t0.342131\n",
      "Recall@K:\t0.155716\n"
     ]
    }
   ],
   "source": [
    "eval_map = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_ndcg = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_precision = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "eval_recall = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
    "\n",
    "print(\"MAP:\\t%f\" % eval_map,\n",
    "      \"NDCG:\\t%f\" % eval_ndcg,\n",
    "      \"Precision@K:\\t%f\" % eval_precision,\n",
    "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
